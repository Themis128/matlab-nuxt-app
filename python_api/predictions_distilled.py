"""
Clean Distilled Model Prediction Endpoint
=========================================

Production-ready distilled decision tree with NO data leakage.

Performance (clean features):
- 12Ã— faster than GBM teacher
- 97.6% smaller (14.5 KB vs 605.5 KB)
- 71.1% accuracy retention (RMSE $32k vs $25k teacher)

Features (18 clean, leakage removed):
- 5 base: RAM, Battery, Screen, Weight, Year
- 13 engineered: ratios, percentiles, interactions
- NO leakage: price_percentile_global, price_elasticity_proxy, cross_brand_price_delta removed

Author: ML Improvement Initiative
Date: 2025-11-30
"""

import numpy as np
import json
from pathlib import Path
from typing import Dict, Optional

try:
    import joblib
    JOBLIB_AVAILABLE = True
except ImportError:
    JOBLIB_AVAILABLE = False

# Paths
MODELS_DIR = Path(__file__).parent / "trained_models"
DISTILLED_MODEL_PATH = MODELS_DIR / "distilled_price_model.pkl"
METADATA_PATH = Path(__file__).parent.parent / "data" / "clean_model_metadata.json"


class DistilledPredictor:
    """Fast, production-ready distilled decision tree (clean features, no leakage)"""

    def __init__(self):
        self.model = None
        self.feature_names = None
        self.categorical_encoders = None
        self.metadata = None
        self._load_model()

    def _load_model(self):
        """Load distilled model and metadata from disk"""
        if not JOBLIB_AVAILABLE:
            print("[WARN] Distilled model unavailable: joblib not installed")
            return

        if not DISTILLED_MODEL_PATH.exists():
            print(f"[WARN] Distilled model not found: {DISTILLED_MODEL_PATH}")
            return

        try:
            # Security: Validate file before loading
            if DISTILLED_MODEL_PATH.stat().st_size > 50 * 1024 * 1024:  # 50MB limit
                print("[ERROR] Model file too large (>50MB)")
                return

            # Only load from trusted paths
            trusted_dirs = ['python_api/trained_models', 'data']
            model_path_abs = str(DISTILLED_MODEL_PATH.resolve()).replace('\\', '/').lower()
            is_trusted = any(trusted_dir.replace('\\', '/').lower() in model_path_abs for trusted_dir in trusted_dirs)

            if not is_trusted:
                print(f"[ERROR] Model file not in trusted directory: {DISTILLED_MODEL_PATH}")
                print(f"[DEBUG] Resolved path: {model_path_abs}")
                print(f"[DEBUG] Trusted dirs: {trusted_dirs}")
                return

            # Load model package with basic validation
            with open(DISTILLED_MODEL_PATH, 'rb') as f:
                # Check if it's a valid pickle file (support protocol 3 and 5)
                header = f.read(2)
                if header not in [b'\x80\x03', b'\x80\x05']:  # Python 3 pickle protocol 3 or 5 header
                    print(f"[ERROR] Invalid pickle file format: {header!r}")
                    return

                # Reset and load
                f.seek(0)
                model_package = joblib.load(f)

            if isinstance(model_package, dict):
                self.model = model_package['model']
                self.feature_names = model_package.get('feature_names', [])
                self.metadata = model_package.get('metadata', {})
            else:
                # Legacy: raw model without packaging
                self.model = model_package
                self.feature_names = []

            # Load clean metadata (feature list, encoders)
            if METADATA_PATH.exists():
                with open(METADATA_PATH, 'r') as f:
                    clean_meta = json.load(f)
                    if not self.feature_names:
                        self.feature_names = clean_meta.get('features', [])
                    self.categorical_encoders = clean_meta.get('categorical_encoders', {})

            print(f"[OK] Distilled model loaded: {len(self.feature_names)} clean features (no leakage)")

        except Exception as e:
            print(f"[ERROR] Failed to load distilled model: {e}")

    def is_available(self) -> bool:
        """Check if model is loaded and ready"""
        return self.model is not None and self.feature_names is not None

    def predict(self, input_data: Dict) -> Dict:
        """
        Predict price using clean distilled model

        Args:
            input_data: Dict with base features (ram, battery, screen, weight, year, company, processor, etc.)

        Returns:
            Dict with predicted_price and model info, or error
        """
        if not self.is_available():
            return {'error': 'Distilled model not available'}

        try:
            # Build feature vector matching training order
            feature_values = []

            for feat_name in self.feature_names:
                # Handle encoded categorical features
                if feat_name.endswith('_encoded'):
                    base_name = feat_name.replace('_encoded', '')

                    # Get value from input (handle different key formats)
                    input_val = None
                    for key in [base_name, base_name.lower(), base_name.replace(' ', '_').lower()]:
                        if key in input_data:
                            input_val = str(input_data[key])
                            break

                    # Encode using label encoder classes
                    if self.categorical_encoders and base_name in self.categorical_encoders:
                        encoder_classes = self.categorical_encoders[base_name]
                        if input_val in encoder_classes:
                            feature_values.append(float(encoder_classes.index(input_val)))
                        else:
                            # Unknown category: use most common (index 0) or middle
                            feature_values.append(float(len(encoder_classes) // 2))
                    else:
                        feature_values.append(0.0)

                # Handle numeric features
                else:
                    # Map feature name to input keys (handle different formats)
                    value = None

                    # Direct match
                    if feat_name in input_data:
                        value = float(input_data[feat_name])

                    # Try lowercase/underscore variants
                    else:
                        key_variants = [
                            feat_name.lower(),
                            feat_name.replace(' ', '_').lower(),
                            feat_name.replace('_', ' ').title()
                        ]
                        for key in key_variants:
                            if key in input_data:
                                value = float(input_data[key])
                                break

                    # Compute derived features if base features available
                    if value is None:
                        value = self._compute_derived_feature(feat_name, input_data)

                    feature_values.append(value if value is not None else 0.0)

            # Predict
            X = np.array(feature_values).reshape(1, -1)
            price_prediction = float(self.model.predict(X)[0])

            return {
                'predicted_price': price_prediction,
                'model': 'distilled_decision_tree_clean',
                'features_used': len(feature_values),
                'leakage_removed': True
            }

        except Exception as e:
            return {'error': f'Prediction failed: {str(e)}'}

    def _compute_derived_feature(self, feat_name: str, input_data: Dict) -> Optional[float]:
        """Compute derived engineered features from base inputs"""

        # Ratios
        if feat_name == 'spec_density':
            if all(k in input_data for k in ['ram', 'battery', 'screen', 'weight']):
                return (input_data['ram'] + input_data['battery']/1000 + input_data['screen']) / max(input_data['weight'], 1)

        elif feat_name == 'temporal_decay':
            if 'year' in input_data:
                age_months = (2025 - input_data['year']) * 12
                return float(np.exp(-age_months / 24))

        elif feat_name.endswith('_weight_ratio'):
            base_feat = feat_name.replace('_weight_ratio', '')
            weight = input_data.get('weight', 1)
            if base_feat == 'battery' and 'battery' in input_data:
                return input_data['battery'] / max(weight, 1)
            elif base_feat == 'screen' and 'screen' in input_data:
                return input_data['screen'] / max(weight, 1)
            elif base_feat == 'ram' and 'ram' in input_data:
                return input_data['ram'] / max(weight, 1)

        elif feat_name == 'ram_battery_interaction_v2':
            if 'ram' in input_data and 'battery' in input_data:
                return input_data['ram'] * (input_data['battery'] / 1000)

        elif feat_name.endswith('_percentile_global'):
            # Approximate percentiles (can't compute without full dataset)
            if 'ram_percentile' in feat_name and 'ram' in input_data:
                return min(input_data['ram'] / 16.0, 1.0)  # Normalize to 16GB max
            elif 'battery_percentile' in feat_name and 'battery' in input_data:
                return min(input_data['battery'] / 6000.0, 1.0)  # Normalize to 6000mAh max

        elif feat_name == 'price_percentile_brand':
            # Approximation: mid-range default
            return 0.5

        elif feat_name == 'spec_value_ratio':
            if all(k in input_data for k in ['ram', 'battery', 'screen']):
                return (input_data['ram'] * 100 + input_data['battery'] + input_data['screen'] * 500) / 10000

        return 0.0  # Default for unknown features

    def get_info(self) -> Dict:
        """Get model information"""
        if not self.is_available():
            return {'available': False}

        return {
            'available': True,
            'model_type': 'DecisionTreeRegressor (distilled, clean)',
            'features_count': len(self.feature_names),
            'features': self.feature_names,
            'leakage_features_removed': ['price_percentile_global', 'price_elasticity_proxy', 'cross_brand_price_delta'],
            'speedup_factor': self.metadata.get('speedup', 12.0) if self.metadata else 12.0,
            'size_reduction_pct': self.metadata.get('size_reduction_pct', 97.6) if self.metadata else 97.6,
            'accuracy_retention_pct': self.metadata.get('accuracy_retention_pct', 71.1) if self.metadata else 71.1,
            'model_path': str(DISTILLED_MODEL_PATH),
            'model_size_kb': 14.5,
            'avg_latency_ms': 0.0,  # Negligible
            'production_ready': True,
            'clean_features': True
        }


# Singleton instance
_distilled_predictor = None


def get_distilled_predictor() -> DistilledPredictor:
    """Get or create distilled predictor singleton"""
    global _distilled_predictor
    if _distilled_predictor is None:
        _distilled_predictor = DistilledPredictor()
    return _distilled_predictor


def predict_price_distilled(input_data: Dict) -> Dict:
    """
    Predict price using fast distilled model (clean features, no leakage)

    Args:
        input_data: Dict with base features:
            - ram: int (GB)
            - battery: int (mAh)
            - screen: float (inches)
            - weight: int (grams)
            - year: int (launch year)
            - company: str (brand name)
            - processor: str (optional)
            - front_camera, back_camera, storage: optional

    Returns:
        Dict with predicted_price (USD) or error

    Example:
        >>> predict_price_distilled({
        ...     'ram': 8, 'battery': 5000, 'screen': 6.5, 'weight': 200,
        ...     'year': 2024, 'company': 'Samsung', 'processor': 'Snapdragon 8 Gen 2'
        ... })
        {'predicted_price': 45230.5, 'model': 'distilled_decision_tree_clean', ...}
    """
    predictor = get_distilled_predictor()
    return predictor.predict(input_data)
